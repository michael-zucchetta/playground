{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "from torchvision.datasets import FashionMNIST\n",
    "from torchvision import transforms\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = FashionMNIST(root=\".\", train=True, download=True, transform=transforms.ToTensor())\n",
    "test_dataset = FashionMNIST(root=\".\", train=False, download=True, transform=transforms.ToTensor())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 28, 28])"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset[0][0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Model, self).__init__()\n",
    "        self.class_size = 10\n",
    "        self.conv_layer_1 =  nn.Conv2d(1, 14, kernel_size=11, stride=2, padding=1, dilation=1)\n",
    "        #self.pool = nn.MaxPool2d(2, 2)\n",
    "        # self.conv_layer_2 = nn.Conv2d(16, 10, (3, 3), 3, 3)\n",
    "        self.conv_layer_2 = nn.Conv2d(14, 10, kernel_size=11, stride=2, padding=1, dilation=1)\n",
    "        self.conv_layer_3 = nn.Conv2d(10, 10, kernel_size=1)\n",
    "        \n",
    "    def forward(self, input_image):\n",
    "        result_1 = F.relu(self.conv_layer_1(input_image))\n",
    "        #print(f'{result_1.shape}: {result_1}')\n",
    "        result_2 = F.relu(self.conv_layer_2(result_1))\n",
    "        result_3 = F.relu(self.conv_layer_3(result_2))\n",
    "        #return F.softmax(result_3, dim=1).squeeze(2).squeeze(2)\n",
    "        return F.log_softmax(result_3, dim=1).squeeze(2).squeeze(2)\n",
    "    \n",
    "class ModelMask(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Model, self).__init__()\n",
    "        self.class_size = 10\n",
    "        self.conv_layer_1 =  nn.Conv2d(1, 14, kernel_size=11, stride=2, padding=1, dilation=1)\n",
    "        #self.pool = nn.MaxPool2d(2, 2)\n",
    "        # self.conv_layer_2 = nn.Conv2d(16, 10, (3, 3), 3, 3)\n",
    "        self.conv_layer_2 = nn.Conv2d(14, 10, kernel_size=11, stride=2, padding=1, dilation=1)\n",
    "        self.conv_layer_3 = nn.Conv2d(10, 10, kernel_size=1)\n",
    "        \n",
    "    def forward(self, input_image):\n",
    "        result_1 = F.relu(self.conv_layer_1(input_image))\n",
    "        #print(f'{result_1.shape}: {result_1}')\n",
    "        result_2 = F.relu(self.conv_layer_2(result_1))\n",
    "        result_3 = F.relu(self.conv_layer_3(result_2))\n",
    "        #return F.softmax(result_3, dim=1).squeeze(2).squeeze(2)\n",
    "        return F.log_softmax(result_3, dim=1).squeeze(2).squeeze(2)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 0\n",
    "\n",
    "model = Model().to(device)\n",
    "\n",
    "net = Net().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "# model.forward(image.view(28, 28, 1, 1))\n",
    "#a = model.forward(image.view(-1))\n",
    "a = model(train_dataset[0][0].view(1, 1, 28, 28).to(device))\n",
    "#pixels = np.asarray(train_dataset[0][0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 10])"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Dimension out of range (expected to be in range of [-2, 1], but got 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-181-6a6f3069f39a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0ma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m: Dimension out of range (expected to be in range of [-2, 1], but got 2)"
     ]
    }
   ],
   "source": [
    "a.squeeze(2).squeeze(2).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [0/60000 (0%)]\tLoss: 2.304036\n",
      "Train Epoch: 1 [5000/60000 (8%)]\tLoss: 0.712879\n",
      "Train Epoch: 1 [10000/60000 (17%)]\tLoss: 0.583876\n",
      "Train Epoch: 1 [15000/60000 (25%)]\tLoss: 0.416198\n",
      "Train Epoch: 1 [20000/60000 (33%)]\tLoss: 0.305618\n",
      "Train Epoch: 1 [25000/60000 (42%)]\tLoss: 0.458283\n",
      "Train Epoch: 1 [30000/60000 (50%)]\tLoss: 0.550277\n",
      "Train Epoch: 1 [35000/60000 (58%)]\tLoss: 0.375713\n",
      "Train Epoch: 1 [40000/60000 (67%)]\tLoss: 0.436687\n",
      "Train Epoch: 1 [45000/60000 (75%)]\tLoss: 0.602333\n",
      "Train Epoch: 1 [50000/60000 (83%)]\tLoss: 0.282566\n",
      "Train Epoch: 1 [55000/60000 (92%)]\tLoss: 0.238015\n",
      "\n",
      "Test set: Average loss: 0.3306, Accuracy: 8740/10000 (87%)\n",
      "\n",
      "Train Epoch: 2 [0/60000 (0%)]\tLoss: 0.354596\n",
      "Train Epoch: 2 [5000/60000 (8%)]\tLoss: 0.337276\n",
      "Train Epoch: 2 [10000/60000 (17%)]\tLoss: 0.188028\n",
      "Train Epoch: 2 [15000/60000 (25%)]\tLoss: 0.423722\n",
      "Train Epoch: 2 [20000/60000 (33%)]\tLoss: 0.325596\n",
      "Train Epoch: 2 [25000/60000 (42%)]\tLoss: 0.307845\n",
      "Train Epoch: 2 [30000/60000 (50%)]\tLoss: 0.235111\n",
      "Train Epoch: 2 [35000/60000 (58%)]\tLoss: 0.563240\n",
      "Train Epoch: 2 [40000/60000 (67%)]\tLoss: 0.306103\n",
      "Train Epoch: 2 [45000/60000 (75%)]\tLoss: 0.312658\n",
      "Train Epoch: 2 [50000/60000 (83%)]\tLoss: 0.337556\n",
      "Train Epoch: 2 [55000/60000 (92%)]\tLoss: 0.293954\n",
      "\n",
      "Test set: Average loss: 0.3038, Accuracy: 8807/10000 (88%)\n",
      "\n",
      "Train Epoch: 3 [0/60000 (0%)]\tLoss: 0.455583\n",
      "Train Epoch: 3 [5000/60000 (8%)]\tLoss: 0.319773\n",
      "Train Epoch: 3 [10000/60000 (17%)]\tLoss: 0.363623\n",
      "Train Epoch: 3 [15000/60000 (25%)]\tLoss: 0.380811\n",
      "Train Epoch: 3 [20000/60000 (33%)]\tLoss: 0.370388\n",
      "Train Epoch: 3 [25000/60000 (42%)]\tLoss: 0.230908\n",
      "Train Epoch: 3 [30000/60000 (50%)]\tLoss: 0.255428\n",
      "Train Epoch: 3 [35000/60000 (58%)]\tLoss: 0.373239\n",
      "Train Epoch: 3 [40000/60000 (67%)]\tLoss: 0.333445\n",
      "Train Epoch: 3 [45000/60000 (75%)]\tLoss: 0.165265\n",
      "Train Epoch: 3 [50000/60000 (83%)]\tLoss: 0.190335\n",
      "Train Epoch: 3 [55000/60000 (92%)]\tLoss: 0.210284\n",
      "\n",
      "Test set: Average loss: 0.2968, Accuracy: 8818/10000 (88%)\n",
      "\n",
      "Train Epoch: 4 [0/60000 (0%)]\tLoss: 0.193072\n",
      "Train Epoch: 4 [5000/60000 (8%)]\tLoss: 0.231585\n",
      "Train Epoch: 4 [10000/60000 (17%)]\tLoss: 0.186863\n",
      "Train Epoch: 4 [15000/60000 (25%)]\tLoss: 0.546836\n",
      "Train Epoch: 4 [20000/60000 (33%)]\tLoss: 0.192385\n",
      "Train Epoch: 4 [25000/60000 (42%)]\tLoss: 0.434982\n",
      "Train Epoch: 4 [30000/60000 (50%)]\tLoss: 0.250038\n",
      "Train Epoch: 4 [35000/60000 (58%)]\tLoss: 0.311087\n",
      "Train Epoch: 4 [40000/60000 (67%)]\tLoss: 0.271268\n",
      "Train Epoch: 4 [45000/60000 (75%)]\tLoss: 0.231548\n",
      "Train Epoch: 4 [50000/60000 (83%)]\tLoss: 0.224393\n",
      "Train Epoch: 4 [55000/60000 (92%)]\tLoss: 0.240818\n",
      "\n",
      "Test set: Average loss: 0.3033, Accuracy: 8809/10000 (88%)\n",
      "\n",
      "Train Epoch: 5 [0/60000 (0%)]\tLoss: 0.270973\n",
      "Train Epoch: 5 [5000/60000 (8%)]\tLoss: 0.301909\n",
      "Train Epoch: 5 [10000/60000 (17%)]\tLoss: 0.177724\n",
      "Train Epoch: 5 [15000/60000 (25%)]\tLoss: 0.211373\n",
      "Train Epoch: 5 [20000/60000 (33%)]\tLoss: 0.252588\n",
      "Train Epoch: 5 [25000/60000 (42%)]\tLoss: 0.188186\n",
      "Train Epoch: 5 [30000/60000 (50%)]\tLoss: 0.385063\n",
      "Train Epoch: 5 [35000/60000 (58%)]\tLoss: 0.417548\n",
      "Train Epoch: 5 [40000/60000 (67%)]\tLoss: 0.207253\n",
      "Train Epoch: 5 [45000/60000 (75%)]\tLoss: 0.139179\n",
      "Train Epoch: 5 [50000/60000 (83%)]\tLoss: 0.275899\n",
      "Train Epoch: 5 [55000/60000 (92%)]\tLoss: 0.309666\n",
      "\n",
      "Test set: Average loss: 0.2906, Accuracy: 8835/10000 (88%)\n",
      "\n",
      "Train Epoch: 6 [0/60000 (0%)]\tLoss: 0.126666\n",
      "Train Epoch: 6 [5000/60000 (8%)]\tLoss: 0.241648\n",
      "Train Epoch: 6 [10000/60000 (17%)]\tLoss: 0.321647\n",
      "Train Epoch: 6 [15000/60000 (25%)]\tLoss: 0.154460\n",
      "Train Epoch: 6 [20000/60000 (33%)]\tLoss: 0.228490\n",
      "Train Epoch: 6 [25000/60000 (42%)]\tLoss: 0.121068\n",
      "Train Epoch: 6 [30000/60000 (50%)]\tLoss: 0.168560\n",
      "Train Epoch: 6 [35000/60000 (58%)]\tLoss: 0.104720\n",
      "Train Epoch: 6 [40000/60000 (67%)]\tLoss: 0.305166\n",
      "Train Epoch: 6 [45000/60000 (75%)]\tLoss: 0.262123\n",
      "Train Epoch: 6 [50000/60000 (83%)]\tLoss: 0.170757\n",
      "Train Epoch: 6 [55000/60000 (92%)]\tLoss: 0.300722\n",
      "\n",
      "Test set: Average loss: 0.2875, Accuracy: 8854/10000 (89%)\n",
      "\n",
      "Train Epoch: 7 [0/60000 (0%)]\tLoss: 0.240300\n",
      "Train Epoch: 7 [5000/60000 (8%)]\tLoss: 0.235529\n",
      "Train Epoch: 7 [10000/60000 (17%)]\tLoss: 0.413850\n",
      "Train Epoch: 7 [15000/60000 (25%)]\tLoss: 0.216918\n",
      "Train Epoch: 7 [20000/60000 (33%)]\tLoss: 0.288981\n",
      "Train Epoch: 7 [25000/60000 (42%)]\tLoss: 0.266955\n",
      "Train Epoch: 7 [30000/60000 (50%)]\tLoss: 0.407092\n",
      "Train Epoch: 7 [35000/60000 (58%)]\tLoss: 0.230331\n",
      "Train Epoch: 7 [40000/60000 (67%)]\tLoss: 0.313228\n",
      "Train Epoch: 7 [45000/60000 (75%)]\tLoss: 0.246883\n",
      "Train Epoch: 7 [50000/60000 (83%)]\tLoss: 0.195231\n",
      "Train Epoch: 7 [55000/60000 (92%)]\tLoss: 0.264782\n",
      "\n",
      "Test set: Average loss: 0.2853, Accuracy: 8851/10000 (89%)\n",
      "\n",
      "Train Epoch: 8 [0/60000 (0%)]\tLoss: 0.228345\n",
      "Train Epoch: 8 [5000/60000 (8%)]\tLoss: 0.355471\n",
      "Train Epoch: 8 [10000/60000 (17%)]\tLoss: 0.304747\n",
      "Train Epoch: 8 [15000/60000 (25%)]\tLoss: 0.322398\n",
      "Train Epoch: 8 [20000/60000 (33%)]\tLoss: 0.177773\n",
      "Train Epoch: 8 [25000/60000 (42%)]\tLoss: 0.315029\n",
      "Train Epoch: 8 [30000/60000 (50%)]\tLoss: 0.253347\n",
      "Train Epoch: 8 [35000/60000 (58%)]\tLoss: 0.226906\n",
      "Train Epoch: 8 [40000/60000 (67%)]\tLoss: 0.453234\n",
      "Train Epoch: 8 [45000/60000 (75%)]\tLoss: 0.199235\n",
      "Train Epoch: 8 [50000/60000 (83%)]\tLoss: 0.302341\n",
      "Train Epoch: 8 [55000/60000 (92%)]\tLoss: 0.204746\n",
      "\n",
      "Test set: Average loss: 0.2877, Accuracy: 8855/10000 (89%)\n",
      "\n",
      "Train Epoch: 9 [0/60000 (0%)]\tLoss: 0.200140\n",
      "Train Epoch: 9 [5000/60000 (8%)]\tLoss: 0.313109\n",
      "Train Epoch: 9 [10000/60000 (17%)]\tLoss: 0.462169\n",
      "Train Epoch: 9 [15000/60000 (25%)]\tLoss: 0.340137\n",
      "Train Epoch: 9 [20000/60000 (33%)]\tLoss: 0.218009\n",
      "Train Epoch: 9 [25000/60000 (42%)]\tLoss: 0.324061\n",
      "Train Epoch: 9 [30000/60000 (50%)]\tLoss: 0.260556\n",
      "Train Epoch: 9 [35000/60000 (58%)]\tLoss: 0.145670\n",
      "Train Epoch: 9 [40000/60000 (67%)]\tLoss: 0.276212\n",
      "Train Epoch: 9 [45000/60000 (75%)]\tLoss: 0.269644\n",
      "Train Epoch: 9 [50000/60000 (83%)]\tLoss: 0.309734\n",
      "Train Epoch: 9 [55000/60000 (92%)]\tLoss: 0.326579\n",
      "\n",
      "Test set: Average loss: 0.2855, Accuracy: 8862/10000 (89%)\n",
      "\n",
      "Train Epoch: 10 [0/60000 (0%)]\tLoss: 0.190977\n",
      "Train Epoch: 10 [5000/60000 (8%)]\tLoss: 0.197334\n",
      "Train Epoch: 10 [10000/60000 (17%)]\tLoss: 0.132368\n",
      "Train Epoch: 10 [15000/60000 (25%)]\tLoss: 0.151687\n",
      "Train Epoch: 10 [20000/60000 (33%)]\tLoss: 0.242461\n",
      "Train Epoch: 10 [25000/60000 (42%)]\tLoss: 0.259572\n",
      "Train Epoch: 10 [30000/60000 (50%)]\tLoss: 0.179943\n",
      "Train Epoch: 10 [35000/60000 (58%)]\tLoss: 0.214621\n",
      "Train Epoch: 10 [40000/60000 (67%)]\tLoss: 0.185787\n",
      "Train Epoch: 10 [45000/60000 (75%)]\tLoss: 0.254050\n",
      "Train Epoch: 10 [50000/60000 (83%)]\tLoss: 0.367612\n",
      "Train Epoch: 10 [55000/60000 (92%)]\tLoss: 0.182526\n",
      "\n",
      "Test set: Average loss: 0.2821, Accuracy: 8853/10000 (89%)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def train(model, device, train_loader, optimizer, epoch):\n",
    "    model.train()\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        # print(f'CICCIO {output.shape}, {target.shape}')\n",
    "        loss = F.nll_loss(output, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if batch_idx % 50 == 0:\n",
    "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "                epoch, batch_idx * len(data), len(train_loader.dataset),\n",
    "                100. * batch_idx / len(train_loader), loss.item()))\n",
    "\n",
    "def test(model, device, test_loader):\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    with torch.no_grad():\n",
    "        for data, target in test_loader:\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            output = model(data)\n",
    "            test_loss += F.nll_loss(output, target, reduction='sum').item() # sum up batch loss\n",
    "            pred = output.max(1, keepdim=True)[1] # get the index of the max log-probability\n",
    "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "\n",
    "    test_loss /= len(test_loader.dataset)\n",
    "    print('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
    "        test_loss, correct, len(test_loader.dataset),\n",
    "        100. * correct / len(test_loader.dataset)))\n",
    "\n",
    "def main():\n",
    "    use_cuda = 0\n",
    "    device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
    "\n",
    "    kwargs = {'num_workers': 2, 'pin_memory': True} if use_cuda else {}\n",
    "    train_loader = torch.utils.data.DataLoader(\n",
    "        datasets.MNIST('../data', train=True, download=True,\n",
    "                       transform=transforms.Compose([\n",
    "                           transforms.ToTensor(),\n",
    "                           transforms.Normalize((0.1307,), (0.3081,))\n",
    "        ])),\n",
    "        batch_size=100, shuffle=True, **kwargs)\n",
    "    test_loader = torch.utils.data.DataLoader(\n",
    "        datasets.MNIST('../data', train=False, transform=transforms.Compose([\n",
    "                           transforms.ToTensor(),\n",
    "                           transforms.Normalize((0.1307,), (0.3081,))\n",
    "])),\n",
    "        batch_size=10, shuffle=True, **kwargs)\n",
    "\n",
    "\n",
    "    model = Model().to(device)\n",
    "    optimizer = optim.SGD(model.parameters(), lr=0.003, momentum=0.9, nesterov=True)\n",
    "\n",
    "    for epoch in range(1, 10 + 1):\n",
    "        train(model, device, train_loader, optimizer, epoch)\n",
    "        test(model, device, test_loader)\n",
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    l = datasets.MNIST('../data', train=True, download=True,\n",
    "                       transform=transforms.Compose([\n",
    "                           transforms.ToTensor(),\n",
    "                           transforms.Normalize((0.1307,), (0.3081,))]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset MNIST\n",
       "    Number of datapoints: 60000\n",
       "    Split: train\n",
       "    Root Location: ../data\n",
       "    Transforms (if any): Compose(\n",
       "                             ToTensor()\n",
       "                             Normalize(mean=(0.1307,), std=(0.3081,))\n",
       "                         )\n",
       "    Target Transforms (if any): None"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 28, 28])"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l[0][0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "Done (t=8.85s)\n",
      "creating index...\n",
      "index created!\n"
     ]
    }
   ],
   "source": [
    "cap = datasets.CocoDetection(root = '/home/none/datasets/coco/train2017',\n",
    "                        annFile = '/home/none/datasets/annotations/stuff_train2017.json',\n",
    "                        transform=transforms.ToTensor())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CC is 0 [Errno 2] No such file or directory: '/home/none/datasets/coco/train2017/000000391895.jpg'\n",
      "CC is 1 [Errno 2] No such file or directory: '/home/none/datasets/coco/train2017/000000522418.jpg'\n",
      "CC is 2 [Errno 2] No such file or directory: '/home/none/datasets/coco/train2017/000000184613.jpg'\n",
      "CC is 3 [Errno 2] No such file or directory: '/home/none/datasets/coco/train2017/000000318219.jpg'\n",
      "CC is 4 [Errno 2] No such file or directory: '/home/none/datasets/coco/train2017/000000554625.jpg'\n",
      "CC is 5 [Errno 2] No such file or directory: '/home/none/datasets/coco/train2017/000000574769.jpg'\n",
      "CC is 6 [Errno 2] No such file or directory: '/home/none/datasets/coco/train2017/000000060623.jpg'\n",
      "CC is 7 [Errno 2] No such file or directory: '/home/none/datasets/coco/train2017/000000309022.jpg'\n"
     ]
    }
   ],
   "source": [
    "s = None\n",
    "for i in range(len(cap)):\n",
    "    try:\n",
    "        s = cap[i]\n",
    "    except BaseException as e:\n",
    "        print(f'CC is {i} {e}')\n",
    "        ()\n",
    "    if s is not None:\n",
    "        break\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'c9n4Q:O10000000000O0101O0000O1001OO1010N100001N1O1WKnEd4S:[KoEd4X:M10O0100O1O010O100O00100O10O0100O1O010O100O10O10K^ElKc:g3^E`L1Ha:h3_E_L1H`:h3`E^L2J]:h3dE[Ld:d3]E[Le:d3\\\\EZLc:g3=M00100O001O10O0100O2N10kDbLi:_3UEcLS:M\\\\F_3@dLS:0\\\\F]3_OeLS:O_F^3ZOdLV:O`Fd3^9`LbF_3]9bLbF^3`9aLaF^3b9`L\\\\Fa3e9^L[Fb3e9^L[Fb3e9_LZF`3g9`LYF_3h9aLYF_3f9aLZF`3e9`LZFX3_OaLS:0RF8<W3e9aLoE8;W3g9aLnE99U3j9cLmE97Q3Q:eLhE97S3Z:PMbE[2HhMNAi:d0XES22hMMAi:^3ZEcL08MGa:0aE2N[3;cLE4e:a3jE[LX:e3`014K4M1O0OGdLQE\\\\3o:dLQE\\\\3o:dLQE[3P;eLPE[3Z;0000O100F_DVMa;j2`DTMa;k2bDSM^;g2`0bMUDh1k;XNWDb1m;]NUD_1n;aNRD\\\\1P<eNPDZ1Q<eNQDZ1o;fNQDZ1o;fNRDX1k;lNVDS1f;POcD_OXOU1S<^OkD`0T;AmD<U;DmD3mNYO[<d0iD2Y;MjD1V;NkD2V;MkD2V;MjD@gNa0`<NkD2U;NkD2U;NjD3V;MkD2U;NkD2U;NkD2V;J`CE\\\\17`;JRUh40^lWKc0J6kA0P=`1_O2M5L3N2M3M3N2M3L4GkLbDZ3_;3000000O2O0000000O2M101O2M2O1O0O13KO21N1^OiD^MW;g1gETNZ:j1kESNZ:IeD0Of1R1_Nf:a1[E\\\\Ng:c1[1EiBiN\\\\=W17N10000O1O1\\\\Od0O1N3L3M3K5N2000Vjg1'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s[1][0]['segmentation']['counts']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pycocotools.coco import COCO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "Done (t=7.90s)\n",
      "creating index...\n",
      "index created!\n"
     ]
    }
   ],
   "source": [
    "coco = COCO('/home/none/datasets/annotations/stuff_train2017.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = coco.annToMask(s[1][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'segmentation': {'counts': 'c9n4Q:O10000000000O0101O0000O1001OO1010N100001N1O1WKnEd4S:[KoEd4X:M10O0100O1O010O100O00100O10O0100O1O010O100O10O10K^ElKc:g3^E`L1Ha:h3_E_L1H`:h3`E^L2J]:h3dE[Ld:d3]E[Le:d3\\\\EZLc:g3=M00100O001O10O0100O2N10kDbLi:_3UEcLS:M\\\\F_3@dLS:0\\\\F]3_OeLS:O_F^3ZOdLV:O`Fd3^9`LbF_3]9bLbF^3`9aLaF^3b9`L\\\\Fa3e9^L[Fb3e9^L[Fb3e9_LZF`3g9`LYF_3h9aLYF_3f9aLZF`3e9`LZFX3_OaLS:0RF8<W3e9aLoE8;W3g9aLnE99U3j9cLmE97Q3Q:eLhE97S3Z:PMbE[2HhMNAi:d0XES22hMMAi:^3ZEcL08MGa:0aE2N[3;cLE4e:a3jE[LX:e3`014K4M1O0OGdLQE\\\\3o:dLQE\\\\3o:dLQE[3P;eLPE[3Z;0000O100F_DVMa;j2`DTMa;k2bDSM^;g2`0bMUDh1k;XNWDb1m;]NUD_1n;aNRD\\\\1P<eNPDZ1Q<eNQDZ1o;fNQDZ1o;fNRDX1k;lNVDS1f;POcD_OXOU1S<^OkD`0T;AmD<U;DmD3mNYO[<d0iD2Y;MjD1V;NkD2V;MkD2V;MjD@gNa0`<NkD2U;NkD2U;NjD3V;MkD2U;NkD2U;NkD2V;J`CE\\\\17`;JRUh40^lWKc0J6kA0P=`1_O2M5L3N2M3M3N2M3L4GkLbDZ3_;3000000O2O0000000O2M101O2M2O1O0O13KO21N1^OiD^MW;g1gETNZ:j1kESNZ:IeD0Of1R1_Nf:a1[E\\\\Ng:c1[1EiBiN\\\\=W17N10000O1O1\\\\Od0O1N3L3M3K5N2000Vjg1',\n",
       "  'size': [479, 640]},\n",
       " 'area': 20396.0,\n",
       " 'iscrowd': 0,\n",
       " 'image_id': 5802,\n",
       " 'bbox': [0.0, 267.0, 520.0, 198.0],\n",
       " 'category_id': 98,\n",
       " 'id': 10007096}"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s[1][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask.sum()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
